{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, inner_channels, stride=1, projection=None):\n",
    "        super(Block, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels, inner_channels, 1, stride=stride, bias=False),\n",
    "                                   nn.BatchNorm2d(inner_channels),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(inner_channels, inner_channels, 3, padding=1, bias=False),\n",
    "                                   nn.BatchNorm2d(inner_channels),\n",
    "                                   nn.Conv2d(inner_channels, inner_channels * self.expansion, 1, bias=False),\n",
    "                                   nn.BatchNorm2d(inner_channels*self.expansion)\n",
    "        )\n",
    "\n",
    "        #Projection is needed to downsample the identity mapping\n",
    "        self.projection = projection\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.projection is not None:\n",
    "            identity = self.projection(x)\n",
    "        \n",
    "        #output is set to be residual\n",
    "        output = self.block(x)\n",
    "        output = self.relu(identity + output)\n",
    "    \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_50(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channel, num_classes):\n",
    "        super(ResNet_50, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv2 = self.make_stage(64, 3)\n",
    "        self.conv3 = self.make_stage(128, 4, stride=2)\n",
    "        self.conv4 = self.make_stage(256, 6, stride=2)\n",
    "        self.conv5 = self.make_stage(512, 3, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def make_stage(self, inner_channels, num_blocks, stride=1):\n",
    "        #Only need projection when dimension is not equal \n",
    "        if stride != 1 or self.in_channels != inner_channels * self.expansion:\n",
    "            projection = nn.Sequential(nn.Conv2d(self.in_channels, inner_channels * self.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                                       nn.BatchNorm2d(inner_channels * self.expansion))\n",
    "        else:\n",
    "            projection = None\n",
    "\n",
    "        layers = []\n",
    "        layers += [Block(self.in_channels, inner_channels, stride=stride, projection=projection)]\n",
    "        self.in_channels = inner_channels * self.expansion\n",
    "\n",
    "        #Only the first layer is needed to be projected\n",
    "        for i in range(1, num_blocks):\n",
    "            layers += [Block(self.in_channels, inner_channels)]\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #first layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        #Second Block \n",
    "        x = self.conv2(x)\n",
    "        #Third Block\n",
    "        x = self.conv3(x)\n",
    "        #Fourth Block\n",
    "        x = self.conv4(x)\n",
    "        #Fifth Block \n",
    "        x = self.conv5(x)\n",
    "\n",
    "        #GAP\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        #Flatten and input to the classifier which is fully connected layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "ResNet_50(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (projection): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (projection): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (projection): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (projection): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=101, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ResNet_50(3, 101).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Food101(root=\"./data\", split=\"train\", transform=transforms, download=False)\n",
    "test_dataset = datasets.Food101(root=\"./data\", split=\"test\", transform=transforms, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], loss: 4.2044, Accuracy: 6.82\n",
      "Epoch [2/50], loss: 3.7192, Accuracy: 13.66\n",
      "Epoch [3/50], loss: 3.2546, Accuracy: 22.10\n",
      "Epoch [4/50], loss: 2.8055, Accuracy: 31.36\n",
      "Epoch [5/50], loss: 2.4455, Accuracy: 38.97\n",
      "Epoch [6/50], loss: 2.1590, Accuracy: 45.31\n",
      "Epoch [7/50], loss: 1.9200, Accuracy: 50.67\n",
      "Epoch [8/50], loss: 1.7179, Accuracy: 55.15\n",
      "Epoch [9/50], loss: 1.5257, Accuracy: 59.57\n",
      "Epoch [10/50], loss: 1.3497, Accuracy: 63.84\n",
      "Epoch [11/50], loss: 1.1576, Accuracy: 68.34\n",
      "Epoch [12/50], loss: 0.9789, Accuracy: 72.79\n",
      "Epoch [13/50], loss: 0.7951, Accuracy: 77.56\n",
      "Epoch [14/50], loss: 0.6319, Accuracy: 81.72\n",
      "Epoch [15/50], loss: 0.4830, Accuracy: 85.77\n",
      "Epoch [16/50], loss: 0.3757, Accuracy: 88.93\n",
      "Epoch [17/50], loss: 0.2966, Accuracy: 91.26\n",
      "Epoch [18/50], loss: 0.2447, Accuracy: 92.66\n",
      "Epoch [19/50], loss: 0.2098, Accuracy: 93.74\n",
      "Epoch [20/50], loss: 0.1869, Accuracy: 94.40\n",
      "Epoch [21/50], loss: 0.1632, Accuracy: 95.10\n",
      "Epoch [22/50], loss: 0.1456, Accuracy: 95.63\n",
      "Epoch [23/50], loss: 0.1401, Accuracy: 95.78\n",
      "Epoch [24/50], loss: 0.1238, Accuracy: 96.31\n",
      "Epoch [25/50], loss: 0.1157, Accuracy: 96.48\n",
      "Epoch [26/50], loss: 0.1105, Accuracy: 96.66\n",
      "Epoch [27/50], loss: 0.1038, Accuracy: 96.81\n",
      "Epoch [28/50], loss: 0.0942, Accuracy: 97.14\n",
      "Epoch [29/50], loss: 0.0927, Accuracy: 97.19\n",
      "Epoch [30/50], loss: 0.0944, Accuracy: 97.17\n",
      "Epoch [31/50], loss: 0.0813, Accuracy: 97.59\n",
      "Epoch [32/50], loss: 0.0825, Accuracy: 97.53\n",
      "Epoch [33/50], loss: 0.0783, Accuracy: 97.63\n",
      "Epoch [34/50], loss: 0.0682, Accuracy: 97.98\n",
      "Epoch [35/50], loss: 0.0688, Accuracy: 97.92\n",
      "Epoch [36/50], loss: 0.0657, Accuracy: 98.04\n",
      "Epoch [37/50], loss: 0.0656, Accuracy: 98.02\n",
      "Epoch [38/50], loss: 0.0632, Accuracy: 98.12\n",
      "Epoch [39/50], loss: 0.0652, Accuracy: 98.06\n",
      "Epoch [40/50], loss: 0.0569, Accuracy: 98.27\n",
      "Epoch [41/50], loss: 0.0555, Accuracy: 98.37\n",
      "Epoch [42/50], loss: 0.0540, Accuracy: 98.38\n",
      "Epoch [43/50], loss: 0.0532, Accuracy: 98.41\n",
      "Epoch [44/50], loss: 0.0545, Accuracy: 98.34\n",
      "Epoch [45/50], loss: 0.0494, Accuracy: 98.49\n",
      "Epoch [46/50], loss: 0.0452, Accuracy: 98.67\n",
      "Epoch [47/50], loss: 0.0481, Accuracy: 98.59\n",
      "Epoch [48/50], loss: 0.0474, Accuracy: 98.54\n",
      "Epoch [49/50], loss: 0.0448, Accuracy: 98.59\n",
      "Epoch [50/50], loss: 0.0410, Accuracy: 98.82\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\joy99\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet_50                                [2, 101]                  --\n",
       "├─Conv2d: 1-1                            [2, 64, 112, 112]         9,408\n",
       "├─BatchNorm2d: 1-2                       [2, 64, 112, 112]         128\n",
       "├─ReLU: 1-3                              [2, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                         [2, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                        [2, 256, 56, 56]          --\n",
       "│    └─Block: 2-1                        [2, 256, 56, 56]          --\n",
       "│    │    └─Sequential: 3-1              [2, 256, 56, 56]          16,896\n",
       "│    │    └─Sequential: 3-2              [2, 256, 56, 56]          58,112\n",
       "│    │    └─ReLU: 3-3                    [2, 256, 56, 56]          --\n",
       "│    └─Block: 2-2                        [2, 256, 56, 56]          --\n",
       "│    │    └─Sequential: 3-4              [2, 256, 56, 56]          70,400\n",
       "│    │    └─ReLU: 3-5                    [2, 256, 56, 56]          --\n",
       "│    └─Block: 2-3                        [2, 256, 56, 56]          --\n",
       "│    │    └─Sequential: 3-6              [2, 256, 56, 56]          70,400\n",
       "│    │    └─ReLU: 3-7                    [2, 256, 56, 56]          --\n",
       "├─Sequential: 1-6                        [2, 512, 28, 28]          --\n",
       "│    └─Block: 2-4                        [2, 512, 28, 28]          --\n",
       "│    │    └─Sequential: 3-8              [2, 512, 28, 28]          132,096\n",
       "│    │    └─Sequential: 3-9              [2, 512, 28, 28]          247,296\n",
       "│    │    └─ReLU: 3-10                   [2, 512, 28, 28]          --\n",
       "│    └─Block: 2-5                        [2, 512, 28, 28]          --\n",
       "│    │    └─Sequential: 3-11             [2, 512, 28, 28]          280,064\n",
       "│    │    └─ReLU: 3-12                   [2, 512, 28, 28]          --\n",
       "│    └─Block: 2-6                        [2, 512, 28, 28]          --\n",
       "│    │    └─Sequential: 3-13             [2, 512, 28, 28]          280,064\n",
       "│    │    └─ReLU: 3-14                   [2, 512, 28, 28]          --\n",
       "│    └─Block: 2-7                        [2, 512, 28, 28]          --\n",
       "│    │    └─Sequential: 3-15             [2, 512, 28, 28]          280,064\n",
       "│    │    └─ReLU: 3-16                   [2, 512, 28, 28]          --\n",
       "├─Sequential: 1-7                        [2, 1024, 14, 14]         --\n",
       "│    └─Block: 2-8                        [2, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-17             [2, 1024, 14, 14]         526,336\n",
       "│    │    └─Sequential: 3-18             [2, 1024, 14, 14]         986,112\n",
       "│    │    └─ReLU: 3-19                   [2, 1024, 14, 14]         --\n",
       "│    └─Block: 2-9                        [2, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-20             [2, 1024, 14, 14]         1,117,184\n",
       "│    │    └─ReLU: 3-21                   [2, 1024, 14, 14]         --\n",
       "│    └─Block: 2-10                       [2, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-22             [2, 1024, 14, 14]         1,117,184\n",
       "│    │    └─ReLU: 3-23                   [2, 1024, 14, 14]         --\n",
       "│    └─Block: 2-11                       [2, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-24             [2, 1024, 14, 14]         1,117,184\n",
       "│    │    └─ReLU: 3-25                   [2, 1024, 14, 14]         --\n",
       "│    └─Block: 2-12                       [2, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-26             [2, 1024, 14, 14]         1,117,184\n",
       "│    │    └─ReLU: 3-27                   [2, 1024, 14, 14]         --\n",
       "│    └─Block: 2-13                       [2, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-28             [2, 1024, 14, 14]         1,117,184\n",
       "│    │    └─ReLU: 3-29                   [2, 1024, 14, 14]         --\n",
       "├─Sequential: 1-8                        [2, 2048, 7, 7]           --\n",
       "│    └─Block: 2-14                       [2, 2048, 7, 7]           --\n",
       "│    │    └─Sequential: 3-30             [2, 2048, 7, 7]           2,101,248\n",
       "│    │    └─Sequential: 3-31             [2, 2048, 7, 7]           3,938,304\n",
       "│    │    └─ReLU: 3-32                   [2, 2048, 7, 7]           --\n",
       "│    └─Block: 2-15                       [2, 2048, 7, 7]           --\n",
       "│    │    └─Sequential: 3-33             [2, 2048, 7, 7]           4,462,592\n",
       "│    │    └─ReLU: 3-34                   [2, 2048, 7, 7]           --\n",
       "│    └─Block: 2-16                       [2, 2048, 7, 7]           --\n",
       "│    │    └─Sequential: 3-35             [2, 2048, 7, 7]           4,462,592\n",
       "│    │    └─ReLU: 3-36                   [2, 2048, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [2, 2048, 1, 1]           --\n",
       "├─Linear: 1-10                           [2, 101]                  206,949\n",
       "==========================================================================================\n",
       "Total params: 23,714,981\n",
       "Trainable params: 23,714,981\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 7.71\n",
       "==========================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 338.79\n",
       "Params size (MB): 94.86\n",
       "Estimated Total Size (MB): 434.85\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(2,3,224,224), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 33.20%\n",
      "Class 1: 40.40%\n",
      "Class 2: 61.20%\n",
      "Class 3: 56.40%\n",
      "Class 4: 60.00%\n",
      "Class 5: 47.20%\n",
      "Class 6: 74.00%\n",
      "Class 7: 72.40%\n",
      "Class 8: 28.40%\n",
      "Class 9: 25.60%\n",
      "Class 10: 36.80%\n",
      "Class 11: 71.60%\n",
      "Class 12: 50.80%\n",
      "Class 13: 74.80%\n",
      "Class 14: 60.40%\n",
      "Class 15: 42.80%\n",
      "Class 16: 49.60%\n",
      "Class 17: 52.40%\n",
      "Class 18: 47.20%\n",
      "Class 19: 52.00%\n",
      "Class 20: 72.40%\n",
      "Class 21: 43.20%\n",
      "Class 22: 35.60%\n",
      "Class 23: 53.20%\n",
      "Class 24: 67.20%\n",
      "Class 25: 70.80%\n",
      "Class 26: 38.00%\n",
      "Class 27: 63.20%\n",
      "Class 28: 63.20%\n",
      "Class 29: 53.60%\n",
      "Class 30: 72.40%\n",
      "Class 31: 43.60%\n",
      "Class 32: 82.80%\n",
      "Class 33: 98.00%\n",
      "Class 34: 74.80%\n",
      "Class 35: 49.60%\n",
      "Class 36: 46.40%\n",
      "Class 37: 30.00%\n",
      "Class 38: 62.00%\n",
      "Class 39: 29.60%\n",
      "Class 40: 74.80%\n",
      "Class 41: 63.60%\n",
      "Class 42: 47.20%\n",
      "Class 43: 22.80%\n",
      "Class 44: 61.60%\n",
      "Class 45: 65.60%\n",
      "Class 46: 52.00%\n",
      "Class 47: 34.00%\n",
      "Class 48: 76.00%\n",
      "Class 49: 38.80%\n",
      "Class 50: 39.60%\n",
      "Class 51: 77.60%\n",
      "Class 52: 61.60%\n",
      "Class 53: 43.60%\n",
      "Class 54: 84.40%\n",
      "Class 55: 49.20%\n",
      "Class 56: 31.60%\n",
      "Class 57: 53.20%\n",
      "Class 58: 34.40%\n",
      "Class 59: 44.80%\n",
      "Class 60: 82.80%\n",
      "Class 61: 66.40%\n",
      "Class 62: 53.60%\n",
      "Class 63: 75.20%\n",
      "Class 64: 79.60%\n",
      "Class 65: 76.80%\n",
      "Class 66: 42.40%\n",
      "Class 67: 40.00%\n",
      "Class 68: 67.60%\n",
      "Class 69: 84.72%\n",
      "Class 70: 72.00%\n",
      "Class 71: 47.20%\n",
      "Class 72: 70.40%\n",
      "Class 73: 37.60%\n",
      "Class 74: 69.20%\n",
      "Class 75: 84.00%\n",
      "Class 76: 73.60%\n",
      "Class 77: 35.60%\n",
      "Class 78: 64.00%\n",
      "Class 79: 72.00%\n",
      "Class 80: 52.80%\n",
      "Class 81: 51.20%\n",
      "Class 82: 38.00%\n",
      "Class 83: 74.80%\n",
      "Class 84: 41.60%\n",
      "Class 85: 50.00%\n",
      "Class 86: 74.80%\n",
      "Class 87: 40.00%\n",
      "Class 88: 76.00%\n",
      "Class 89: 59.60%\n",
      "Class 90: 69.20%\n",
      "Class 91: 71.60%\n",
      "Class 92: 58.40%\n",
      "Class 93: 32.40%\n",
      "Class 94: 76.00%\n",
      "Class 95: 61.60%\n",
      "Class 96: 50.00%\n",
      "Class 97: 58.00%\n",
      "Class 98: 71.20%\n",
      "Class 99: 32.40%\n",
      "Class 100: 44.00%\n",
      "Overall Test Accuracy : 56.61%\n"
     ]
    }
   ],
   "source": [
    "class_correct = torch.zeros(101, device=device)\n",
    "class_total = torch.zeros(101, device=device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label]  += (predicted[i] == label).float()\n",
    "            class_total[label] += 1\n",
    "\n",
    "        \n",
    "for i in range(101):\n",
    "    if class_total[i] > 0:\n",
    "        print(f\"Class {i}: {100 * class_correct[i] / class_total[i]:.2f}%\")\n",
    "\n",
    "accuracy = 100 * class_correct.sum() / class_total.sum()\n",
    "print(f\"Overall Test Accuracy : {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
